# -*- coding: utf-8 -*-
"""Machine Learning Terapan - Sistem Rekomendasi.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1m8XMF9wmEcJaJfiswZXI2OnQdnmLlj2z

# **Sistem Rekomendasi: Cellphones Recommendation**

# **Deskripsi Proyek**
Proyek ini bertujuan untuk mengembangkan model machine learning yang dapat memberikan rekomendasi cell phones kepada seseorang. Saat ini, masih banyak orang yang tidak mengetahui cell phone yang cocok untuk mereka gunakan sesuai dengan kebutuhan. Dengan adanya sistem rekomendasi ini diharapkan dapat membantu seseorang menemukan ponsel yang paling sesuai dengan kebutuhan mereka, baik dari segi performa, harga, maupun fitur lainnya.

Import Library yang dibutuhkan
"""

from google.colab import files
import zipfile
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
from pathlib import Path

"""# **Data Understanding**

---

Data Understanding merupakan proses memahami informasi dalam data dan menentukan kualitas dari data tersebut.

**Informasi Dataset**
      
| Jenis  | Keterangan |
| ------------- |-------------|
| Title      | Cellphones Recommendations |
| Source      | [Kaggle](https://www.kaggle.com/datasets/meirnizri/cellphones-recommendations/data) |
| Maintainer      | Meir Nizri |
| License | Database: Open Database |
| Visibility | Publik |
| Tags | Pre-Trained Model, Electronics, E-commerce Services, Mobile and Wireless, System Recommendations |
| Usability | 10.00 |

Melakukan download dataset dari Github pribadi
"""

#Download dataset
!wget https://raw.githubusercontent.com/syfeigipcul45/machine-learning-terapan-sistem_rekomendasi/main/dataset/dataset.zip

"""melakukan unzip file dataset karena masih dalam bentuk file .zip"""

#Unzip dataset
!unzip dataset.zip

#Mengubah nama file
!mv '/content/cellphones data.csv' 'data.csv'
!mv '/content/cellphones ratings.csv' 'rating.csv'
!mv '/content/cellphones users.csv' 'users.csv'

#Menghapus file zip
!rm dataset.zip

"""mengubah nama file dataset dan menghapus file dataset.zip"""

data = pd.read_csv('data.csv')
rating = pd.read_csv('rating.csv')
users = pd.read_csv('users.csv')

"""# **Univariate Exploratory Data Analysis**

---

Pada tahap ini melakukan analisis dan eksplorasi setiap variabel pada data.
"""

#menampilkan 5 data dari dataset data
data.head()

data.info()

"""Dari eksekusi method data.info() di atas kita dapat melihat bahwa pada dataset ini terdapat 14 kolom.

* Terdapat 8 kolom numerik dengan tipe data int64 yaitu: cellphone_id, internal memory, RAM, main camera, selfie camera, battery size, weight, dan price.
* Terdapat 2 kolom dengan tipe data float64 yaitu: performance, screen size.
* Terdapat 1 kolom dengan tipe data object yaitu: release date

Penjelasan tiap kolom:
* ```cellphone_id:``` ID unik untuk setiap ponsel.
* ```brand:``` Merek ponsel.
* ```model:``` Model ponsel.
* ```operating system:``` Sistem operasi ponsel.
* ```internal memory:``` Memori internal ponsel dalam GB.
* ```RAM:``` RAM ponsel dalam GB.
* ```performance:``` Skor kinerja ponsel.
* ```main camera:``` Resolusi kamera utama dalam MP.
* ```selfie camera:``` Resolusi kamera depan dalam MP.
* ```battery size:``` Kapasitas baterai dalam mAh.
* ```screen size:``` Ukuran layar dalam inci.
* ```weight:``` Berat ponsel dalam gram.
* ```price:``` Harga ponsel dalam USD.
* ```release date:``` Tanggal rilis ponsel.
"""

#mengecek missing value
data.isnull().sum()

#mengecek data duplicate
data.duplicated().sum()

#menampilkan 5 data dari dataset users
users.head()

users.info()

"""Dari eksekusi method users.info() di atas kita dapat melihat bahwa pada dataset ini terdapat 4 kolom.

* Terdapat 2 kolom numerik dengan tipe data int64 yaitu: user_id, dan age.
* Terdapat 2 kolom dengan tipe data object yaitu: gender dan occupation.

Penjelasan tiap kolom:
* ```user_id:``` ID unik untuk setiap pengguna.
* ```age:``` Usia pengguna.
* ```gender:``` Jenis kelamin pengguna.
* ```occupation:``` Pekerjaan pengguna.
"""

#mengecek missing value
users.isnull().sum()

"""Terdapat 1 missing value pada kolom occupation"""

#mengecek data duplicate
users.duplicated().sum()

#menampilkan 5 data dari dataset rating
rating.head()

rating.info()

"""Dari eksekusi method rating.info() di atas kita dapat melihat bahwa pada dataset ini terdapat 3 kolom.

* semua kolom memiliki tipe data int64 yaitu: user_id, cellphone_id, dan rating.

Penjelasan tiap kolom:
* ```user_id:``` ID unik untuk setiap pengguna.
* ```cellphone_id:``` ID unik untuk setiap ponsel (mengacu pada cellphones_data).
* ```rating:``` Rating yang diberikan pengguna untuk ponsel tertentu (skala 1-10).
"""

#menampilkan missing value
rating.isnull().sum()

#menampilkan duplicate data
rating.duplicated().sum()

"""**Dataset Data**

---

Menghitung jumlah brand dan cellphone pada masing-masing brand
"""

#Menghitung jumlah brand
print('Banyak brand: ',len(data.brand.unique()))
print('Tipe brand: ', data.brand.unique())

#Menghitung jumlah cellphone masing-masing brand
brand_counts = data['brand'].value_counts()
print(brand_counts)

#Menampilkan dalam bentuk grafik
plt.figure(figsize=(5, 3))
sns.countplot(data=data, x=data['brand'])
plt.xticks(rotation=90)
plt.show()

"""Berdasarkan gambar diatas terdapat:
* jumlah brand sebanyak 10
* Samsung adalah brand terbanyak
* Asus, Oppo, Vivo, Sony adalah brand paling sedikit
"""

#Menghitung jumlah model
print('Banyak model: ',len(data.model.unique()))
print('Tipe model: ', data.model.unique())

"""Model cellphones ada 33 model"""

#Menghitung jumlah operating system
os_counts = data['operating system'].value_counts()
print(os_counts)

"""Terdapat 2 kategori operating system: Android dan iOS"""

#Menghitung jumlah internal memory
internalMemory_counts = data['internal memory'].value_counts()
print(internalMemory_counts)

#Menampilkan dalam bentuk grafik
plt.figure(figsize=(5, 3))
sns.countplot(data=data, x=data['internal memory'])
plt.show()

"""Berdasarkan gambar diatas terdapat:
* 5 kategori internal memory
* total ada 20 dengan kategori internal memory 128
* hanya ada 1 dengan kategori internal memory 512
"""

#Menghitung jumlah internal memory
ram_counts = data['RAM'].value_counts()
print(ram_counts)

#Menampilkan dalam bentuk grafik
plt.figure(figsize=(5, 3))
sns.countplot(data=data, x=data['RAM'])
plt.show()

"""Berdasarkan gambar diatas terdapat:
* 5 kategori RAM
* total ada 13 dengan kategori RAM 8GB
* kategori 3GB dan 12GB memiliki jumlah paling sedikit dengan total 4

**Dataset Users**

---
"""

#Menghitung age muncul berapa kali
age_counts = users['age'].value_counts()
print("\nJumlah kemunculan age:\n", age_counts.sort_index())

#Menampilkan grafik
plt.figure(figsize=(10, 3))
sns.countplot(data=users, x=users['age'])
plt.show()

"""Berdasarkan hasil diatas:
* Umur paling muda adalah 21 tahun
* Umur paling tua adalah 61 tahun
"""

#Menghitung gender muncul berapa kali
gender_counts = users['gender'].value_counts()
print("\nJumlah kemunculan gender:\n", gender_counts)

#Menampilkan grafik
plt.figure(figsize=(10, 3))
sns.countplot(data=users, x=users['gender'])
plt.show()

"""Berdasarkan hasil diatas:
* Gender Male sebanyak 50
* Gender Female sebanyak 46
* Terdapat outliers yaitu ```-Select Gender-``` sebanyak 3
"""

#Menghitung occupation muncul berapa kali
occupation_counts = users['occupation'].str.lower().value_counts()
print("Jumlah occupation: ", len(occupation_counts))
print("\nJumlah kemunculan occupation:\n", occupation_counts.sort_index())

"""Berdasarkan informasi diatas:
* Jumlah pekerjaan sebanyak 45 jenis pekerjaan
* Terdapat kesalahan pada penulisan ```healthare```
* Pekerjaan ```it``` dan ```information technology``` dapat dijadikan satu

**Dataset Rating**

---

Melihat distribusi rating pada data, gunakan fungsi describe() dengan menerapkan kode berikut:
"""

rating.describe()

rating_counts = rating['rating'].value_counts()
print("\nJumlah kemunculan per rating:\n", rating_counts.sort_index())

#Menampilkan grafik
plt.figure(figsize=(5, 3))
sns.countplot(data=rating, x=rating['rating'])
plt.show()

"""Dari output diatas terdapat:
* skala rating 1-10
* rating terendah adalah 1
* rating tertinggi adalah 10
* terdapat nilai outliers yaitu nilai rating 18
"""

print('Jumlah userID: ', len(rating.user_id.unique()))
print('Jumlah cellphonesID: ', len(rating.cellphone_id.unique()))
print('Jumlah data rating: ', len(rating))

"""# **Data Preprocessing**

---

Menggabungkan dataset data, rating, dan users menjadi satu.
"""

#Gabungkan cellphones_ratings dengan cellphones_data
rating_data = pd.merge(rating, data, on='cellphone_id', how='left')

#Gabungkan hasil dengan cellphones_users
cellphone = pd.merge(rating_data, users, on='user_id', how='left')

#Menampilkan dataset hasil merged
cellphone.head()

cellphone.info()

"""Hasil output diatas merupakan hasil dari penggabungan dataset data, rating, dan user.

# **Data Preparation**

---

Melakukan pengecekan missing value pada dataset
"""

cellphone.isnull().sum()

"""Berdasarkan output diatas, terdapat 10 missing value pada kolom ```occupation```

Menampilkan baris yang memiliki nilai null
"""

rows_with_null = cellphone[cellphone.isnull().any(axis=1)]
print(rows_with_null)

"""Berdasarkan informasi diatas ditemukan saat univariate analysis bahwa terdapat outlier pada kolom gender yaitu ```-Select Gender-``` yang ternyata berhubungan dengan nilai occupation ```NaN```

Menghapus nilai missing value
"""

#Menghapus missing value
cellphone = cellphone.dropna()

"""Cek kembali data apakah masih terdapat missing value"""

cellphone.isnull().sum()

"""Sudah tidak ada lagi data missing value

Berdasarkan dari ```Univariate Exploratory Data Analysis``` terdapat ouliers pada kolom ```rating```, terdapat kesalahan penulisan jenis pekerjaan pada kolom ```occupation``` serta menyamakan nama jenis pekerjaan.
"""

#Drop rating 18
cellphone = cellphone[cellphone['rating'] != 18]

#Mengubah seluruh nilai occupation menjadi lowercase
cellphone['occupation'] = cellphone['occupation'].str.lower()

#Mengubah nilai 'healthare' menjadi 'healthcare'
cellphone['occupation'] = cellphone['occupation'].replace('healthare', 'healthcare')

#Mengubah nilai 'it' menjadi 'information technology'
cellphone['occupation'] = cellphone['occupation'].replace('it', 'information technology')

new_cellphone = cellphone
new_cellphone.sort_values('cellphone_id')

"""Selanjutnya, menggunakan data unik untuk dimasukkan ke dalam proses pemodelan. Oleh karena itu, perlu menghapus data yang duplikat dengan fungsi ```drop_duplicates()```. Dalam hal ini, kita membuang data duplikat pada kolom ```cellphone_id```."""

new_cellphone = new_cellphone.drop_duplicates('cellphone_id')
new_cellphone

"""Melakukan konversi data series menjadi list. Dalam hal ini, kita menggunakan fungsi ```tolist()``` dari library numpy"""

#Melakukan konversi data series menjadi list
cellphone_id = new_cellphone['cellphone_id'].tolist()
brand = new_cellphone['brand'].tolist()
model = new_cellphone['model'].tolist()
operating_system = new_cellphone['operating system'].tolist()

print(len(cellphone_id))
print(len(brand))
print(len(model))
print(len(operating_system))

"""Membuat dictionary untuk menentukan pasangan key-value pada data cellphone_id, brand, model, dan operating system.

Parameter yang digunakan:
* TF-IDF Vectorizer: Untuk mengubah deskripsi teks menjadi vektor numerik.
* Cosine Similarity: Untuk menghitung kesamaan antara vektor item.

TF-IDF hanya cocok untuk data teks maka hanya kolom yang bertipe object saja yang dipilih.
"""

phone_new = pd.DataFrame({
    'cellphone_id': cellphone_id,
    'brand': brand,
    'model': model,
    'operating_system': operating_system,
})

phone_new.head()

"""# **Model Development Dengan Content Based Filtering**

---


"""

data = phone_new
data.head()

"""**TF-IDF Vectorizer**

Membangun sistem rekomendasi
"""

#Inisialisasi TfidfVectorizer
tf = TfidfVectorizer()

#Melakukan perhitungan idf pada data brand
tf.fit(data['brand'])

#Mapping array dari fitur index integer ke fitur nama
tf.get_feature_names_out()

"""Selanjutnya, lakukan fit dan transformasi ke dalam bentuk matriks."""

# Melakukan fit lalu ditransformasikan ke bentuk matrix
tfidf_matrix = tf.fit_transform(data['brand'])

# Melihat ukuran matrix tfidf
tfidf_matrix.shape

"""matriks memiliki ukuran (33, 10). Nilai 33 merupakan ukuran data dan 10 merupakan matrik kategori brand.

Untuk menghasilkan vektor tf-idf dalam bentuk matriks
"""

#Menghasilkan vektor TF-IDF dalam bentuk matriks.
tfidf_matrix.todense()

"""Melihat matriks TF-IDF untuk beberapa model dan brand."""

# Membuat dataframe untuk melihat tf-idf matrix
# Kolom diisi dengan jenis model
# Baris diisi dengan nama brand

pd.DataFrame(
    tfidf_matrix.todense(),
    columns=tf.get_feature_names_out(),
    index=data.model
).sample(10, axis=1).sample(10, axis=0)

"""**Cosine Similarity**

Menghitung derajat kesamaan (similarity degree) dengan teknik cosine similarity.
"""

# Menghitung cosine similarity pada matrix tf-idf
cosine_sim = cosine_similarity(tfidf_matrix)
cosine_sim

"""Melihat matriks kesamaan setiap model dengan menampilkan nama model dalam 33 sampel kolom (axis = 1) dan 10 sampel baris (axis=0)"""

# Membuat dataframe dari variabel cosine_sim dengan baris dan kolom berupa nama model
cosine_sim_df = pd.DataFrame(cosine_sim, index=data['model'], columns=data['model'])
print('Shape:', cosine_sim_df.shape)

# Melihat similarity matrix pada setiap resto
cosine_sim_df.sample(5, axis=1).sample(10, axis=0)

"""Shape (33, 33) merupakan ukuran matriks similarity. Berdasarkan data yang ada, matriks di atas sebenarnya berukuran 33 model x 33 model (masing-masing dalam sumbu X dan Y). Disini hanya memilih 10 model pada baris vertikal dan 5 model pada sumbu horizontal seperti pada contoh di atas.

**Membuat Rekomendasi**

membuat fungsi ```resto_recommendations``` dengan beberapa parameter sebagai berikut:

* ```model``` : Nama model (index kemiripan dataframe).
* ```similarity_data``` : Dataframe mengenai similarity yang telah kita definisikan sebelumnya.
* ```items``` : Nama dan fitur yang digunakan untuk mendefinisikan kemiripan, dalam hal ini adalah ```'model'```, ```'brand'``` dan ```'operating_system'```.
* ```k``` : Banyak rekomendasi yang ingin diberikan.
"""

def model_recommendations(model, similarity_data=cosine_sim_df, items=data[['model', 'brand', 'operating_system']], k=5):
        # Mengambil data dengan menggunakan argpartition untuk melakukan partisi secara tidak langsung sepanjang sumbu yang diberikan
    # Dataframe diubah menjadi numpy
    # Range(start, stop, step)
    index = similarity_data.loc[:,model].to_numpy().argpartition(
        range(-1, -k, -1))

    # Mengambil data dengan similarity terbesar dari index yang ada
    closest = similarity_data.columns[index[-1:-(k+2):-1]]

    # Drop nama_resto agar nama resto yang dicari tidak muncul dalam daftar rekomendasi
    closest = closest.drop(model, errors='ignore')

    return pd.DataFrame(closest).merge(items).head(k)

#Menampilkan hasil rekomendasi
model_recommendations('Moto G Play (2021)')

#Menampilkan hasil rekomendasi
model_recommendations('X80 Pro')

# Contoh ponsel yang direkomendasikan untuk Phone A
recommended_phones = model_recommendations("Moto G Play (2021)")
# Convert the 'model' column of the DataFrame to a list
recommended_phone_list = recommended_phones["model"].tolist()
print("Rekomendasi untuk Moto G Play (2021):", recommended_phone_list)

# Daftar ponsel yang relevan (misalnya ponsel dengan merek yang sama dengan X80 Pro)
# Assuming 'data' is your DataFrame and 'model' is the column with phone models
# Accessing the brand column: data[data['model'] == 'X80 Pro']['brand'].iloc[0]
relevant_phones = data[data["brand"] == data[data["model"] == "Moto G Play (2021)"]["brand"].iloc[0]]["model"].tolist()

# Hitung precision
relevant_and_recommended = [phone for phone in recommended_phone_list if phone in relevant_phones]
precision = len(relevant_and_recommended) / len(recommended_phone_list) if len(recommended_phone_list) > 0 else 0

print("Daftar ponsel relevan:", relevant_phones)
print("Ponsel yang direkomendasikan:", recommended_phone_list)
print("Precision:", precision)

"""# **Model Development dengan Collaborative Filtering**

---

Model Development dengan Collaborative Filtering menghasilkan rekomendasi sejumlah model yang sesuai dengan preferensi pengguna berdasarkan rating yang telah diberikan sebelumnya.

**Data Understanding**

membaca dataset rating
"""

df = rating
df

"""data rating memiliki 990 baris dan 3 kolom

**Data Preparation**

melakukan persiapan data untuk menyandikan (encode) fitur ```'user_id'``` dan ```'cellphone_id'``` ke dalam indeks integer.
"""

# Mengubah user_id menjadi list tanpa nilai yang sama
user_ids = df['user_id'].unique().tolist()
print('list userID: ', user_ids)

# Melakukan encoding userID
user_to_user_encoded = {x: i for i, x in enumerate(user_ids)}
print('encoded userID : ', user_to_user_encoded)

# Melakukan proses encoding angka ke ke userID
user_encoded_to_user = {i: x for i, x in enumerate(user_ids)}
print('encoded angka ke userID: ', user_encoded_to_user)

#Mengubah cellphone_id menjadi list tanpa nilai yang sama
cellphone_ids = df['cellphone_id'].unique().tolist()

#Melakukan proses encoding cellphone_id
cellphone_to_cellphone_encoded = {x: i for i, x in enumerate(cellphone_ids)}

#Melakukan proses encoding angka ke cellphone_id
cellphone_encoded_to_cellphone = {i: x for i, x in enumerate(cellphone_ids)}

"""Berikutnya, petakan userID dan cellphoneID ke dataframe yang berkaitan"""

# Mapping userID ke dataframe user
df['user'] = df['user_id'].map(user_to_user_encoded)

# Mapping placeID ke dataframe resto
df['cellphone'] = df['cellphone_id'].map(cellphone_to_cellphone_encoded)

"""Cek beberapa hal dalam data seperti jumlah user, jumlah cellphone, dan mengubah nilai rating menjadi float."""

# Mendapatkan jumlah user
num_users = len(user_to_user_encoded)
print(num_users)

# Mendapatkan jumlah cellphone
num_cellphone = len(cellphone_encoded_to_cellphone)
print(num_cellphone)

# Mengubah rating menjadi nilai float
df['rating'] = df['rating'].values.astype(np.float32)

# Nilai minimum rating
min_rating = min(df['rating'])

# Nilai maksimal rating
max_rating = max(df['rating'])

print('Number of User: {}, Number of cellphone: {}, Min Rating: {}, Max Rating: {}'.format(
    num_users, num_cellphone, min_rating, max_rating
))

"""Output kode di atas memberikan informasi :

* Jumlah user 99
* Jumlah cellphone 33
* min rating: 1, max rating: 18
* Terdapat outliers pada fitur rating yaitu value '18'

Menghapus data outliers
"""

#Drop data
df = df[df['rating'] != 18]

"""Mengecek kembali nilai minimal dan maksimal rating"""

#Nilai minimum rating
min_rating = min(df['rating'])

#Nilai maksimal rating
max_rating = max(df['rating'])

print('Min Rating: {}, Max Rating: {}'.format(
    min_rating, max_rating
))

"""Rating sudah sesuai

**Membagi data untuk Training dan Validasi**
"""

# Mengacak dataset
df = df.sample(frac=1, random_state=42)
df

"""Membagi data train dan validasi dengan komposisi 80:20. Kemudian memetakan (mapping) data user dan cellphone menjadi satu value terlebih dahulu. Lalu, buatlah rating dalam skala 0 sampai 1 agar mudah dalam melakukan proses training."""

# Membuat variabel x untuk mencocokkan data user dan cellphone menjadi satu value
x = df[['user', 'cellphone']].values

# Membuat variabel y untuk membuat rating dari hasil
y = df['rating'].apply(lambda x: (x - min_rating) / (max_rating - min_rating)).values

# Membagi menjadi 80% data train dan 20% data validasi
train_indices = int(0.8 * df.shape[0])
x_train, x_val, y_train, y_val = (
    x[:train_indices],
    x[train_indices:],
    y[:train_indices],
    y[train_indices:]
)

print(x, y)

"""# **Proses Training**

---

Membuat class ```RecommenderNet``` dengan keras Model class.
"""

class RecommenderNet(tf.keras.Model):

  # Insialisasi fungsi
  def __init__(self, num_users, num_cellphone, embedding_size, **kwargs):
    super(RecommenderNet, self).__init__(**kwargs)
    self.num_users = num_users
    self.num_cellphone = num_cellphone
    self.embedding_size = embedding_size
    self.user_embedding = layers.Embedding( # layer embedding user
        num_users,
        embedding_size,
        embeddings_initializer = 'he_normal',
        embeddings_regularizer = keras.regularizers.l2(1e-6)
    )
    self.user_bias = layers.Embedding(num_users, 1) # layer embedding user bias
    self.cellphone_embedding = layers.Embedding( # layer embeddings cellphone
        num_cellphone,
        embedding_size,
        embeddings_initializer = 'he_normal',
        embeddings_regularizer = keras.regularizers.l2(1e-6)
    )
    self.cellphone_bias = layers.Embedding(num_cellphone, 1) # layer embedding cellphone bias

  def call(self, inputs):
    user_vector = self.user_embedding(inputs[:,0]) # memanggil layer embedding 1
    user_bias = self.user_bias(inputs[:, 0]) # memanggil layer embedding 2
    cellphone_vector = self.cellphone_embedding(inputs[:, 1]) # memanggil layer embedding 3
    cellphone_bias = self.cellphone_bias(inputs[:, 1]) # memanggil layer embedding 4

    dot_user_cellphone = tf.tensordot(user_vector, cellphone_vector, 2)

    x = dot_user_cellphone + user_bias + cellphone_bias

    return tf.nn.sigmoid(x) # activation sigmoid

"""Melakukan proses compile terhadap model."""

model = RecommenderNet(num_users, num_cellphone, 50) # inisialisasi model

# model compile
model.compile(
    loss = tf.keras.losses.BinaryCrossentropy(),
    optimizer = keras.optimizers.Adam(learning_rate=0.001),
    metrics=[tf.keras.metrics.RootMeanSquaredError()]
)

"""Model ini menggunakan Binary Crossentropy untuk menghitung loss function, Adam (Adaptive Moment Estimation) sebagai optimizer, dan root mean squared error (RMSE) sebagai metrics evaluation.

Memulai proses training
"""

# Memulai training

history = model.fit(
    x = x_train,
    y = y_train,
    batch_size = 8,
    epochs = 100,
    validation_data = (x_val, y_val)
)

"""**Visualisasi Metrik**"""

#Menampilkan grafik traning vs test
plt.plot(history.history['root_mean_squared_error'])
plt.plot(history.history['val_root_mean_squared_error'])
plt.title('model_metrics')
plt.ylabel('root_mean_squared_error')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()

"""RMSE yang dihitung memberikan indikasi bahwa model prediksi rating memiliki tingkat kesalahan yang dapat diterima, sehingga memadai untuk tujuan rekomendasi.

**Mendapatkan Rekomendasi Cellphone**
"""

phone_df = phone_new
df = pd.read_csv('rating.csv')

#Mengambil sample user
user_id = df.user_id.sample(1).iloc[0]
cellphone_reviewed_by_user = df[df.user_id == user_id]

cellphone_not_reviewed = phone_df[~phone_df['cellphone_id'].isin(cellphone_reviewed_by_user.cellphone_id.values)]['cellphone_id']
cellphone_not_reviewed = list(
    set(cellphone_not_reviewed)
    .intersection(set(cellphone_to_cellphone_encoded.keys()))
)

cellphone_not_reviewed = [[cellphone_to_cellphone_encoded.get(x)] for x in cellphone_not_reviewed]
user_encoder = user_to_user_encoded.get(user_id)
user_cellphone_array = np.hstack(
    ([[user_encoder]] * len(cellphone_not_reviewed), cellphone_not_reviewed)
)

"""Memperoleh hasil rekomendasi cellphone"""

ratings = model.predict(user_cellphone_array).flatten()

top_ratings_indices = ratings.argsort()[-10:][::-1]
recommended_cellphone_ids = [
    cellphone_encoded_to_cellphone.get(cellphone_not_reviewed[x][0]) for x in top_ratings_indices
]

print('Showing recommendations for users: {}'.format(user_id))
print('===' * 9)
print('cellphone with high ratings from user')
print('----' * 8)

top_cellphone_user = (
    cellphone_reviewed_by_user.sort_values(
        by = 'rating',
        ascending=False
    )
    .head(5)
    .cellphone_id.values
)

cellphone_df_rows = phone_df[phone_df['cellphone_id'].isin(top_cellphone_user)]
for row in cellphone_df_rows.itertuples():
    print(row.brand, ':', row.model)

print('----' * 8)
print('Top 10 cellphone recommendation')
print('----' * 8)

recommended_cellphone = phone_df[phone_df['cellphone_id'].isin(recommended_cellphone_ids)]
for row in recommended_cellphone.itertuples():
    print(row.brand, ':', row.model)